{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase I: Detailed Data Exploration - SQuAD v1.1\n",
                "\n",
                "This notebook provides a comprehensive analysis of the Stanford Question Answering Dataset (SQuAD) v1.1. We will explore dataset statistics, length distributions, and answer patterns to inform our model choices and preprocessing hyperparameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\My Device\\Desktop\\Question Answering with Transformers_NLP\\localenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                },
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'matplotlib'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
                    ]
                }
            ],
            "source": [
                "from datasets import load_dataset\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import json\n",
                "import numpy as np\n",
                "\n",
                "sns.set_theme(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Downloading SQuAD v1.1 dataset...\")\n",
                "dataset = load_dataset(\"squad\")\n",
                "dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset Overview\n",
                "\n",
                "Let's look at the basic statistics of the train and validation splits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "splits = ['train', 'validation']\n",
                "summary = []\n",
                "\n",
                "for split in splits:\n",
                "    df = dataset[split].to_pandas()\n",
                "    summary.append({\n",
                "        'Split': split,\n",
                "        'Total Records': len(df),\n",
                "        'Unique Contexts': df['context'].nunique(),\n",
                "        'Unique Titles': df['title'].nunique()\n",
                "    })\n",
                "\n",
                "pd.DataFrame(summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Length Analysis\n",
                "\n",
                "Understanding the distribution of context, question, and answer lengths is crucial for setting `max_length` in tokenization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = dataset['train'].to_pandas()\n",
                "\n",
                "# Calculate lengths in words (approximation of tokens)\n",
                "train_df['context_len'] = train_df['context'].apply(lambda x: len(x.split()))\n",
                "train_df['question_len'] = train_df['question'].apply(lambda x: len(x.split()))\n",
                "train_df['answer_len'] = train_df['answers'].apply(lambda x: len(x['text'][0].split()))\n",
                "\n",
                "train_df[['context_len', 'question_len', 'answer_len']].describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualizing Distributions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "sns.histplot(train_df['context_len'], bins=50, ax=axes[0], color='skyblue')\n",
                "axes[0].set_title('Context Length Distribution (Words)')\n",
                "axes[0].set_xlabel('Words')\n",
                "\n",
                "sns.histplot(train_df['question_len'], bins=30, ax=axes[1], color='salmon')\n",
                "axes[1].set_title('Question Length Distribution (Words)')\n",
                "axes[1].set_xlabel('Words')\n",
                "\n",
                "sns.histplot(train_df['answer_len'], bins=20, ax=axes[2], color='lightgreen')\n",
                "axes[2].set_title('Answer Length Distribution (Words)')\n",
                "axes[2].set_xlabel('Words')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Topic Analysis\n",
                "\n",
                "What are the most frequent topics in the training set?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "train_df['title'].value_counts()[:15].plot(kind='barh', color='darkblue')\n",
                "plt.title('Top 15 Topics in SQuAD v1.1')\n",
                "plt.xlabel('Count')\n",
                "plt.ylabel('Title')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Sample Record Inspection\n",
                "\n",
                "Let's look at a few examples, including a long context and a short context."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"--- Long Context Example ---\")\n",
                "long_sample = train_df.sort_values(by='context_len', ascending=False).iloc[0]\n",
                "print(f\"Title: {long_sample['title']}\")\n",
                "print(f\"Context Length: {long_sample['context_len']} words\")\n",
                "print(f\"Question: {long_sample['question']}\")\n",
                "print(f\"Answer: {long_sample['answers']['text'][0]}\")\n",
                "\n",
                "print(\"\\n--- Short Context Example ---\")\n",
                "short_sample = train_df.sort_values(by='context_len', ascending=True).iloc[0]\n",
                "print(f\"Title: {short_sample['title']}\")\n",
                "print(f\"Context Length: {short_sample['context_len']} words\")\n",
                "print(f\"Question: {short_sample['question']}\")\n",
                "print(f\"Answer: {short_sample['answers']['text'][0]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Sample for Reference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = \"data\"\n",
                "os.makedirs(data_dir, exist_ok=True)\n",
                "\n",
                "sample_record = dataset['train'][0]\n",
                "with open(os.path.join(data_dir, \"squad_sample.json\"), \"w\") as f:\n",
                "    json.dump(sample_record, f, indent=4)\n",
                "\n",
                "print(f\"Sample saved to {os.path.join(data_dir, 'squad_sample.json')}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "localenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
